---
generator: pandoc
title: Regresi√≥n lineal simple y m√∫ltiple
viewport: width=device-width, initial-scale=1
---

::: {style="visibility: hidden; overflow: hidden; position: absolute; top: 0px; height: 1px; width: auto; padding: 0px; border: 0px; margin: 0px; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal;"}
::: {#MathJax_Hidden}
:::
:::

::: {#MathJax_Message style="display: none;"}
:::

::: {.container-fluid .main-container}
::: {#header}
# Regresi√≥n lineal simple y m√∫ltiple {#regresi√≥n-lineal-simple-y-m√∫ltiple .title .toc-ignore}

### Ejemplo de soluci√≥n ejercicio pr√°tico N¬∞9 {#ejemplo-de-soluci√≥n-ejercicio-pr√°tico-n9 .subtitle}
:::

::: {#enunciado .section .level2}
## Enunciado

::: enunciado
Un estudio recolect√≥ medidas anat√≥micas de 247 hombres y 260 mujeres
(Heinz et al., 2003). El estudio incluy√≥ nueve mediciones del esqueleto
(ocho di√°metros y una profundidad de hueso a hueso) y doce mediciones de
grosor (di√°metros de circunferencias) que incluyen el tejido.

La siguiente tabla detalla las variables registradas en este estudio:

  Variable                  Descripci√≥n                                                                                    Unidad
  ------------------------- ---------------------------------------------------------------------------------------------- ---------------------
  Biacromial.diameter       Di√°metro biacromial (a la altura de los hombros)                                               cm
  Biiliac.diameter          Di√°metro biiliaco (a la altura de la pelvis)                                                   cm
  Bitrochanteric.diameter   Di√°metro bitrocant√©reo (a la altura de las caderas)                                            cm
  Chest.depth               Profundidad del pecho (entre la espina y el estern√≥n a la altura de los pezones)               cm
  Chest.diameter            Di√°metro del pecho (a la altura de los pezones)                                                cm
  Elbows.diameter           Suma de los di√°metros de los codos                                                             cm
  Wrists.diameter           Suma de los di√°metros de las mu√±ecas                                                           cm
  Knees.diameter            Suma de los di√°metros de las rodillas                                                          cm
  Ankles.diameter           Suma de los di√°metros de los tobillos                                                          cm
  Shoulder.Girth            Grosor de los hombros sobre los m√∫sculos deltoides                                             cm
  Chest.Girth               Grosor del pecho, sobre tejido mamario en mujeres y a la altura de los pezones en varones      cm
  Waist.Girth               Grosor a la altura de la cintura                                                               cm
  Navel.Girth               Grosor a la altura del ombligo                                                                 cm
  Hip.Girth                 Grosor a la altura de las caderas                                                              cm
  Thigh.Girth               Grosor promedio de ambos muslos bajo el pliegue del gl√∫teo                                     cm
  Bicep.Girth               Grosor promedio de ambos b√≠ceps, brazos flectados                                              cm
  Forearm.Girth             Grosor promedio de ambos antebrazos, brazos extendidos palmas hacia arriba                     cm
  Knee.Girth                Grosor promedio de ambas rodillas, posici√≥n levemente flectada, medici√≥n arriba de la r√≥tula   cm
  Calf.Maximum.Girth        Grosor promedio de la parte m√°s ancha de ambas pantorrillas                                    cm
  Ankle.Minimum.Girth       Grosor promedio de la parte m√°s delgada de ambos tobillos                                      cm
  Wrist.Minimum.Girth       Grosor promedio de la parte m√°s delgada de ambas mu√±ecas                                       cm
  Age                       Edad                                                                                           A√±os
  Weight                    Peso                                                                                           Kg
  Height                    Estatura                                                                                       cm
  Gender                    G√©nero                                                                                         1: hombre, 0: mujer

Con estos datos se pide construir un modelo de regresi√≥n lineal m√∫ltiple
para predecir una *variable respuesta*, de acuerdo con las siguientes
instrucciones:

1.  Definir la semilla a utilizar, que corresponde a los √∫ltimos cuatro
    d√≠gitos del RUN (sin considerar el d√≠gito verificador) del
    integrante de menor edad del equipo.
2.  Seleccionar una muestra de 100 mujeres (si la semilla es un n√∫mero
    par) o 100 hombres (si la semilla es impar), y separar 70 casos para
    trabajar en la construcci√≥n de modelos y 30 para su evaluaci√≥n en
    datos no vistos.
3.  Seleccionar de forma aleatoria ocho posibles variables predictoras.
4.  Seleccionar, de las otras variables, una que el equipo considere que
    podr√≠a ser √∫til para predecir la variable respuesta, justificando
    bien esta selecci√≥n.
5.  Usando el entorno R y paquetes est√°ndares, construir un modelo de
    regresi√≥n lineal simple con el predictor seleccionado en el paso
    anterior.
6.  Usando herramientas est√°ndares para la exploraci√≥n de modelos del
    entorno R, buscar entre dos y cinco predictores de entre las
    variables seleccionadas al azar en el punto 3, para agregar al
    modelo de regresi√≥n lineal simple obtenido en el paso 5.
7.  Evaluar la bondad de ajuste (incluyendo el an√°lisis de casos
    at√≠picos y casos influyentes) y la generalidad (condiciones para
    RLM) de los modelos y "arreglarlos" en caso de que presenten alg√∫n
    problema.
8.  Evaluar el poder predictivo de los modelos en datos no utilizados
    para construirlos.
:::

\

Comencemos incluyendo los paquetes que usaremos en este script.

``` r
library(car)
library(dplyr)
library(ggpubr)
library(psych)
```

Obtengamos los datos en formato ancho.

``` r
src_dir <- "~/Downloads"
# src_dir <- "C:/Users/ProfeJLJara/Downloads"
src_basename <- "EP09 Datos.csv"
src_file <- file.path(src_dir, src_basename)

datos <- read.csv2(file = src_file, stringsAsFactors = TRUE)
```

Obtengamos la muestra y separ√©mosla en los conjuntos de entrenamiento y
prueba, teniendo el cuidado de fijar una semilla para su
reproductibilidad.

``` r
set.seed(1111)
datos <- datos |> filter(Gender == 1) |> select(-Gender) |> sample_n(100, replace = FALSE)
datos_entren <- datos[1:70, ]
datos_prueba <- datos[71:100, ]
```

Para este script de ejemplo, usaremos como variable respuesta **los
di√°metros de las rodillas** (`Knees.diameter`).

Corresponde seleccionar al azar 8 posibles variables predictoras de este
conjunto, teniendo cuidado de no seleccionar la variable de respuesta.

``` r
nombre_respuesta <- "Knees.diameter"
variables <- colnames(datos_entren)
i_respuesta <- which(variables == nombre_respuesta)
predictores <- sample(variables[-i_respuesta], 8, replace = FALSE)

cat("Predictores seleccionados al azar:\n")
cat(paste(predictores, collapse = "\n"))
```

``` bg-ivory
Predictores seleccionados al azar:
Ankles.diameter
Calf.Maximum.Girth
Waist.Girth
Bitrochanteric.diameter
Ankle.Minimum.Girth
Hip.Girth
Biiliac.diameter
Age
```

Estos son los predictores seleccionados al azar para ser considerados en
el modelo de regresi√≥n lineal m√∫ltiple que vamos a construir.

Para seleccionar una de las variables restantes para construir un modelo
de regresi√≥n lineal simple (RLS), vamos a evaluar su correlaci√≥n con la
variable respuesta.

``` r
datos_resto <- datos_entren |> select(!all_of(predictores))
i_respuesta_resto <- which(colnames(datos_resto) == nombre_respuesta)
correlacion <- cor(datos_resto[-i_respuesta_resto], y = datos_resto[[nombre_respuesta]])

cat("Correlaci√≥n con la variable respuesta:\n")
print(correlacion)
```

``` bg-ivory
Correlaci√≥n con la variable respuesta:
                         [,1]
Biacromial.diameter 0.4990345
Chest.depth         0.1833036
Chest.diameter      0.5305838
Elbows.diameter     0.5616106
Wrists.diameter     0.6259288
Shoulder.Girth      0.4762599
Chest.Girth         0.3594377
Navel.Girth         0.2803497
Thigh.Girth         0.5622237
Bicep.Girth         0.3890932
Forearm.Girth       0.5044949
Knee.Girth          0.6105291
Wrist.Minimum.Girth 0.4510171
Weight              0.6174914
Height              0.4652410
```

Asumiendo que el mejor predictor para un modelo de RLS es aquella
variable con mayor correlaci√≥n (directa o inversa) con la variable de
respuesta, podemos determinar f√°cilmente nuestro predictor.

``` r
i_mejor <- which(correlacion == max(abs(correlacion)))
predictor <- rownames(correlacion)[i_mejor]

cat("Variable m√°s correlacionada con la variable respuesta:", predictor, "\n")
```

``` bg-ivory
Variable m√°s correlacionada con la variable respuesta: Wrists.diameter 
```

Filtramos para quedarnos con las variables relevantes.

``` r
datos_entren <- datos_entren |>
  select(all_of(c(predictor, predictores, nombre_respuesta)))
```
:::

::: {#regresi√≥n-lineal-simple .section .level2}
## Regresi√≥n lineal simple

Demos entonces una mirada a los datos.

``` r
p1 <- ggscatter(datos_entren, x = predictor, y = nombre_respuesta,
                color = "steelblue", fill = "steelblue",
                add = "reg.line", add.params = list(color = "red"))
print(p1)
```

Este gr√°fico de dispersi√≥n parece mostrar una relaci√≥n lineal positiva
entre las variables.

Obtengamos el modelo de regresi√≥n lineal simple.

``` r
fmla <- formula(paste(nombre_respuesta, predictor, sep = " ~ "))
rls <- lm(fmla, data = datos_entren)

cat("Modelo de regresi√≥n lineal simple:\n")
print(summary(rls))
```

``` bg-ivory
Modelo de regresi√≥n lineal simple:

Call:
lm(formula = fmla, data = datos_entren)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.23465 -0.52636  0.04165  0.55385  1.93549 

Coefficients:
                Estimate Std. Error t value Pr(>|t|)    
(Intercept)       6.4357     2.0056   3.209  0.00203 ** 
Wrists.diameter   1.1754     0.1776   6.618 6.86e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.9409 on 68 degrees of freedom
Multiple R-squared:  0.3918,    Adjusted R-squared:  0.3828 
F-statistic:  43.8 on 1 and 68 DF,  p-value: 6.86e-09
```

Podemos ver que el modelo de RLS obtenido explica alrededor del 40% de la varianza en los datos y que es significativamente mejor que simplemente usar la media (ùêπ(1,68)=43,8; ùëù<0,001).

Revisemos los gr√°ficos de los residuos que genera el modelo.

``` r
cat("Prueba de curvatura:\n")
residualPlots(rls, type = "rstandard", terms = ~ 1, col = "steelblue", pch = 20, col.quad = "red")
```


``` bg-ivory
Prueba de curvatura:
           Test stat Pr(>|Test stat|)
Tukey test   -0.0499           0.9602
```

Vemos que no hay un patr√≥n identificable y que los residuos parecen
repartirse de forma aleatoria arriba y abajo de la l√≠nea de regresi√≥n.
La prueba de curvatura resultan no significativas, por lo que no podemos
descartar que el di√°metro de las mu√±ecas se relaciona linealmente con el
di√°metro de las rodillas.

Si tuvi√©ramos dudas, podemos confirmar la normalidad de los residuos con
un histograma y usando una prueba de normalidad.

``` r
h_res <- gghistogram(data.frame(Residuos = resid(rls)), x = "Residuos", bins = 11,
                     fill = "steelblue")
print(h_res)
```

``` r
sw_res <- shapiro.test(resid(rls))
cat("Test de normalidad de los residuos del modelo de RLS:")
print(sw_res)
```

``` bg-ivory
Test de normalidad de los residuos del modelo de RLS:
    Shapiro-Wilk normality test

data:  resid(rls)
W = 0.98444, p-value = 0.5373
```

Si bien se observa cierta asimetr√≠a, no hay evidencia suficiente para
descartar que los residuos siguen un comportamiento normal.

Confirmemos que la varianza de los residuos se mantienen constante.

``` r
cat("Prueba de varianza del error no constante:\n")
ncvTest(rls)
```

``` bg-ivory
Prueba de varianza del error no constante:
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.7204959, Df = 1, p = 0.39598
```

No se puede descartar entonces que los residuos cumplan con la condici√≥n de homocedasticidad (ùúí(1)=0,720; ùëù=0,396).

Revisemos que los residuos se comportan de manera independiente como
siguiere su gr√°fico.

``` r
cat("Independencia de los residuos\n")
print(durbinWatsonTest(rls))
```

``` bg-ivory
Independencia de los residuos
 lag Autocorrelation D-W Statistic p-value
   1    -0.003277224      2.003726   0.972
 Alternative hypothesis: rho != 0
```

Confirmamos que no es posible descartar que la condici√≥n de independencia no se est√© cumpliendo en este modelo(D-W=2,004; ùëù=0,972).

Evaluemos ahora las estad√≠sticas de influencia del modelo de RLS
obtenido.

``` r
cat("Rango para 95% de los residuos studentizados: ")
cat("[", round(qt(0.05/2, nrow(datos_entren) - length(coef(rls)) - 1), 3), ", ", sep = "")
cat(round(qt(1-0.05/2, nrow(datos_entren) - length(coef(rls)) - 1), 3), "]\n", sep = "")
cat("L√≠mite del apalancamiento:", round(2 * mean(hatvalues(rls)), 3), "\n")
cat("L√≠mite de la distancia de Cook:", round(3 * mean(cooks.distance(rls)), 3), "\n")

rls_inf <- influencePlot(rls, id = list(n = 3))
```


``` r
cat("\nCasos notorios para el modelo de RLS:\n")
print(rls_inf)
```

``` bg-ivory
Rango para 95% de los residuos studentizados: [-1.996, 1.996]
L√≠mite del apalancamiento: 0.057 
L√≠mite de la distancia de Cook: 0.041 

Casos notorios para el modelo de RLS:
      StudRes        Hat       CookD
4   0.1522091 0.16027504 0.002243178
10 -2.2423594 0.01483604 0.035743448
22  2.1279933 0.01699401 0.037211819
26 -0.9842297 0.09706282 0.052090459
31 -1.8813672 0.05166403 0.092943592
43 -0.8710547 0.09706282 0.040926056
44 -2.4820614 0.01483604 0.043115757
66  1.9826195 0.07676569 0.156667225
```

El procedimiento detecta 8 casos que podr√≠an estar influyendo
excesivamente en los coeficientes del modelo de RLS obtenido. Revisemos
si podemos identificar si estos casos potencialmente problem√°ticos est√°n
distorsionando el modelo.

``` r
crPlots(rls, ylim = c(-2.3, 3.3),
        col = "steelblue", pch = 20, col.lines = c("red", "steelblue"),
        smooth = list(smoother = loessLine, span = 1),
        id = list(method = "r", n = 8, cex = 0.7, location = "lr"))
```

Vemos que en realidad no parece
haber un apalancamiento indebido de alguno de estos casos. Podr√≠amos
sospechar del caso 66, pero su potencial influencia parece
contrarrestada por valores cercanos, pero por debajo de la l√≠nea de
regresi√≥n. Para comprobar, podemos revisar c√≥mo luce el modelo de RLS
sin ese dato.

``` r
rls2 <- lm(fmla, data = datos_entren[-66, ])
crPlots(rls2, ylim = c(-2.3, 3.3),
        col = "steelblue", pch = 20, col.lines = c("red", "steelblue"),
        smooth = list(smoother = loessLine, span = 1),
        id = list(method = "r", n = 8, cex = 0.7, location = "lr"))
```

style="display: block; margin: auto;"} Podemos ver que el nuevo modelo
es pr√°cticamente igual al original, por lo que no parece necesario
quitar casos. Hagamos una conclusi√≥n entonces.

::: conclusion
El modelo obtenido parece confiable, ya que genera residuos aleatorios y no es posible descartar que sigan una distribuci√≥n normal, usando un predictor que muestra una relaci√≥n lineal con la variable respuesta. Tampoco se identifican casos que est√©n ejerciendo demasiada influencia en el modelo.

Por otro lado, el modelo consigue una bondad de ajuste aceptable, pues explica alrededor del 40%de la variabilidad en la variable predicha, que es una reducci√≥n significativa (ùêπ(1;68)=43,8; ùëù<0,001).

\
:::

::: {#regresi√≥n-lineal-m√∫ltiple .section .level2}
## Regresi√≥n lineal m√∫ltiple

Para cumplir con la instrucci√≥n 6, vamos a utilizar la estrategia de
regresi√≥n escalonada implementada en la funci√≥n `step()`. Para eso
usaremos nuestro modelo de RLS como modelo m√≠nimo, y como modelo m√°ximo
el que utiliza todos los predictores que seleccionamos anteriormente de
forma aleatoria.

``` r
rlm_max_text <- paste(c(predictor, predictores), collapse = " + ")
rlm_max_fmla <- formula(paste(nombre_respuesta, rlm_max_text, sep = " ~ "))
rlm_max <- lm(rlm_max_fmla, data = datos_entren)

rlm <- step(rls, scope = list(lower = rls, upper = rlm_max), direction = "both")
```

``` bg-ivory
Start:  AIC=-6.56
Knees.diameter ~ Wrists.diameter

                          Df Sum of Sq    RSS      AIC
+ Bitrochanteric.diameter  1   12.4092 47.786 -20.7231
+ Hip.Girth                1   10.4109 49.785 -17.8554
+ Calf.Maximum.Girth       1   10.0993 50.096 -17.4186
+ Biiliac.diameter         1    7.0482 53.147 -13.2800
+ Age                      1    6.2971 53.898 -12.2978
+ Ankle.Minimum.Girth      1    5.6329 54.562 -11.4404
+ Ankles.diameter          1    5.6137 54.582 -11.4157
<none>                                 60.195  -6.5630
+ Waist.Girth              1    0.0460 60.149  -4.6165

Step:  AIC=-20.72
Knees.diameter ~ Wrists.diameter + Bitrochanteric.diameter

                          Df Sum of Sq    RSS     AIC
+ Age                      1    7.8451 39.941 -31.276
+ Calf.Maximum.Girth       1    3.4070 44.379 -23.901
+ Ankles.diameter          1    2.8811 44.905 -23.076
+ Hip.Girth                1    2.2880 45.498 -22.157
<none>                                 47.786 -20.723
+ Waist.Girth              1    1.0187 46.768 -20.231
+ Ankle.Minimum.Girth      1    0.6749 47.111 -19.719
+ Biiliac.diameter         1    0.0020 47.784 -18.726
- Bitrochanteric.diameter  1   12.4092 60.195  -6.563

Step:  AIC=-31.28
Knees.diameter ~ Wrists.diameter + Bitrochanteric.diameter + 
    Age

                          Df Sum of Sq    RSS     AIC
+ Ankles.diameter          1    4.9650 34.976 -38.568
+ Hip.Girth                1    2.6861 37.255 -34.150
+ Calf.Maximum.Girth       1    2.0896 37.851 -33.038
<none>                                 39.941 -31.276
+ Ankle.Minimum.Girth      1    0.3802 39.561 -29.946
+ Waist.Girth              1    0.1107 39.830 -29.471
+ Biiliac.diameter         1    0.0138 39.927 -29.300
- Age                      1    7.8451 47.786 -20.723
- Bitrochanteric.diameter  1   13.9572 53.898 -12.298

Step:  AIC=-38.57
Knees.diameter ~ Wrists.diameter + Bitrochanteric.diameter + 
    Age + Ankles.diameter

                          Df Sum of Sq    RSS     AIC
+ Hip.Girth                1    2.1781 32.798 -41.069
<none>                                 34.976 -38.568
+ Calf.Maximum.Girth       1    0.7429 34.233 -38.071
+ Waist.Girth              1    0.1285 34.848 -36.826
+ Ankle.Minimum.Girth      1    0.0982 34.878 -36.765
+ Biiliac.diameter         1    0.0536 34.922 -36.676
- Ankles.diameter          1    4.9650 39.941 -31.276
- Age                      1    9.9290 44.905 -23.076
- Bitrochanteric.diameter  1   10.5384 45.515 -22.132

Step:  AIC=-41.07
Knees.diameter ~ Wrists.diameter + Bitrochanteric.diameter + 
    Age + Ankles.diameter + Hip.Girth

                          Df Sum of Sq    RSS     AIC
+ Waist.Girth              1    1.3737 31.424 -42.064
+ Ankle.Minimum.Girth      1    1.2790 31.519 -41.853
<none>                                 32.798 -41.069
+ Biiliac.diameter         1    0.4357 32.362 -40.005
+ Calf.Maximum.Girth       1    0.0131 32.785 -39.097
- Hip.Girth                1    2.1781 34.976 -38.568
- Bitrochanteric.diameter  1    3.7028 36.501 -35.581
- Ankles.diameter          1    4.4570 37.255 -34.150
- Age                      1   10.2067 43.005 -24.103

Step:  AIC=-42.06
Knees.diameter ~ Wrists.diameter + Bitrochanteric.diameter + 
    Age + Ankles.diameter + Hip.Girth + Waist.Girth

                          Df Sum of Sq    RSS     AIC
+ Ankle.Minimum.Girth      1    1.3769 30.047 -43.200
<none>                                 31.424 -42.064
- Waist.Girth              1    1.3737 32.798 -41.069
+ Biiliac.diameter         1    0.2812 31.143 -40.693
+ Calf.Maximum.Girth       1    0.0113 31.413 -40.089
- Bitrochanteric.diameter  1    2.8260 34.250 -38.036
- Age                      1    3.3467 34.771 -36.980
- Hip.Girth                1    3.4233 34.848 -36.826
- Ankles.diameter          1    3.9079 35.332 -35.859

Step:  AIC=-43.2
Knees.diameter ~ Wrists.diameter + Bitrochanteric.diameter + 
    Age + Ankles.diameter + Hip.Girth + Waist.Girth + Ankle.Minimum.Girth

                          Df Sum of Sq    RSS     AIC
<none>                                 30.047 -43.200
+ Calf.Maximum.Girth       1    0.4969 29.551 -42.367
+ Biiliac.diameter         1    0.4652 29.582 -42.292
- Ankle.Minimum.Girth      1    1.3769 31.424 -42.064
- Waist.Girth              1    1.4716 31.519 -41.853
- Bitrochanteric.diameter  1    3.4375 33.485 -37.618
- Age                      1    3.8746 33.922 -36.710
- Hip.Girth                1    4.5894 34.637 -35.250
- Ankles.diameter          1    5.2218 35.269 -33.984
```

El modelo obtenido no cumple con lo solicitado en el enunciado, pues
tiene un predictor m√°s de lo permitido. Comencemos identificando un
predictor para ser eliminado.

``` r
drop1(rlm, test = "F")
```

``` bg-ivory
Single term deletions

Model:
Knees.diameter ~ Wrists.diameter + Bitrochanteric.diameter + 
    Age + Ankles.diameter + Hip.Girth + Waist.Girth + Ankle.Minimum.Girth
                        Df Sum of Sq    RSS     AIC F value   Pr(>F)   
<none>                               30.047 -43.200                    
Wrists.diameter          1    4.3025 34.350 -35.833  8.8779 0.004118 **
Bitrochanteric.diameter  1    3.4375 33.485 -37.618  7.0930 0.009847 **
Age                      1    3.8746 33.922 -36.710  7.9948 0.006309 **
Ankles.diameter          1    5.2218 35.269 -33.984 10.7747 0.001693 **
Hip.Girth                1    4.5894 34.637 -35.250  9.4698 0.003108 **
Waist.Girth              1    1.4716 31.519 -41.853  3.0365 0.086372 . 
Ankle.Minimum.Girth      1    1.3769 31.424 -42.064  2.8410 0.096913 . 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

Vemos que el menor cambio en AIC ocurre eliminando el predictor Ankle.Minimum.Girth, que lleva a un modelo equivalente en cuanto a variabilidad no explicada (ùêπ(1,62)=2,841;ùëù=0,097). Quitemos esta variable.

``` r
rlm <- update(rlm, . ~ . - Ankle.Minimum.Girth)
```

Evaluemos la confiabilidad del modelo de RLM conseguido. Comencemos
revisando que no exista niveles inaceptables de **multicolinealidad**.

``` r
cat("Factores de inflaci√≥n de la varianza:\n")
print(vif(rlm))
cat("Estad√≠sticos de tolerancia:\n")
print(1 / vif(rlm))
```

``` bg-ivory
Factores de inflaci√≥n de la varianza:
        Wrists.diameter Bitrochanteric.diameter                     Age 
               1.643894                1.950384                1.645266 
        Ankles.diameter               Hip.Girth             Waist.Girth 
               1.456971                4.454118                4.021333 
Estad√≠sticos de tolerancia:
        Wrists.diameter Bitrochanteric.diameter                     Age 
              0.6083116               0.5127195               0.6078046 
        Ankles.diameter               Hip.Girth             Waist.Girth 
              0.6863554               0.2245114               0.2486737 
```

Vemos que, en general, solo hay indicios de multicolinealidad
*moderada*, pues solo dos predictores presentan valores de inflaci√≥n de
la varianza sobre 4. Probablemente estas dos variables est√°n
correlacionadas. Eliminemos la que presenta el mayor valor.

``` r
rlm <- update(rlm, . ~ . - Hip.Girth)

cat("Factores de inflaci√≥n de la varianza:\n")
print(vif(rlm))
cat("Estad√≠sticos de tolerancia:\n")
print(1 / vif(rlm))
```

``` bg-ivory
Factores de inflaci√≥n de la varianza:
        Wrists.diameter Bitrochanteric.diameter                     Age 
               1.643792                1.492344                1.319838 
        Ankles.diameter             Waist.Girth 
               1.433072                1.701800 
Estad√≠sticos de tolerancia:
        Wrists.diameter Bitrochanteric.diameter                     Age 
              0.6083494               0.6700870               0.7576686 
        Ankles.diameter             Waist.Girth 
              0.6978018               0.5876132 
```

Muy bien, hemos eliminado gran parte de la multicolinealidad presente en
el modelo anterior manteniendo 4 predictores nuevos agregados al modelo
de RLS creado anteriormente.

Revisemos los residuos que genera este modelo.

``` r
cat("Prueba de curvatura:\n")
residualPlots(rlm, type = "rstandard", terms = ~ 1, col = "steelblue", pch = 20, col.quad = "red")
```

``` bg-ivory
Prueba de curvatura:
           Test stat Pr(>|Test stat|)
Tukey test    1.5919           0.1114
```

Se ve cierta curvatura, pero que podr√≠a deberse a falta de observaciones
en la muestra con di√°metros de rodillas bajo los 18 o sobre los 21,5 cm.
En el rango entre estos valores, no se ve un patr√≥n preocupante, aunque
existe cierta tendencia a patrones por sobre la l√≠nea de regresi√≥n. La
prueba de curvatura tambi√©n apunta en este sentido.

Revisemos la normalidad de estos residuos.

``` r
qq_res <- ggqqplot(data.frame(Residuos = resid(rlm)), x = "Residuos", color = "steelblue")
print(qq_res)
```

``` r
sw_res <- shapiro.test(resid(rlm))
cat("Test de normalidad de los residuos del modelo de RLM:")
print(sw_res)
```

``` bg-ivory
Test de normalidad de los residuos del modelo de RLM:
    Shapiro-Wilk normality test

data:  resid(rlm)
W = 0.98203, p-value = 0.413
```

Vemos que los residuos parecen seguir una distribuci√≥n normal, con algunos casos en el l√≠mite, pero que no son suficientes para permitir descartar que se cumple esta condici√≥n (ùëä=0,982; ùëù=0.413).

Ahora verifiquemos la varianza e independencia de los residuos.

``` r
cat("Prueba de varianza del error no constante:\n")
ncvTest(rlm)

cat("\nIndependencia de los residuos\n")
print(durbinWatsonTest(rlm))
```

``` bg-ivory
Prueba de varianza del error no constante:
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.3385501, Df = 1, p = 0.56067

Independencia de los residuos
 lag Autocorrelation D-W Statistic p-value
   1       0.1604509      1.668819   0.156
 Alternative hypothesis: rho != 0
```

Con esto confirmamos que no es posible descartar que se est√°n cumpliendo las condiciones de homogeneidad de la varianza (ùúí(1)=0,339; ùëù=0,561) e independencia de los residuos (D-W=1,669; ùëù=0,156).

Revisemos si existen relaciones *aproximadamente* lineales entre los
predictores y la variable de inter√©s.

``` r
crPlots(rlm,
        col = "steelblue", pch = 20, col.lines=c("red", "steelblue"),
        smooth = list(smoother=loessLine, span = 1),
        id = list(method = "r", n = 3, cex = 0.7, location = "lr"))
```

Observamos que las relaciones
parecen aproximadamente lineales, aunque alguna duda puede quedar con
c√≥mo se distribuyen los residuos al considerar la variable `Waist.Girth`
(grosor de la cintura). Tambi√©n podemos notar que la recta de regresi√≥n
parcial para este predictor tiene una pendiente muy baja, abriendo dudas
de su aporte. Revisemos su contribuci√≥n en relaci√≥n a los otros
predictores.

``` r
cat("Modelo de RLM obtenido:\n")
print(summary(rlm))
```

``` bg-ivory
Modelo de RLM obtenido:

Call:
lm(formula = Knees.diameter ~ Wrists.diameter + Bitrochanteric.diameter + 
    Age + Ankles.diameter + Waist.Girth, data = datos_entren)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.62930 -0.43887  0.05634  0.48511  1.55466 

Coefficients:
                         Estimate Std. Error t value Pr(>|t|)    
(Intercept)              1.418884   1.930894   0.735  0.46513    
Wrists.diameter          0.565732   0.178570   3.168  0.00235 ** 
Bitrochanteric.diameter  0.223152   0.055878   3.994  0.00017 ***
Age                     -0.043533   0.010848  -4.013  0.00016 ***
Ankles.diameter          0.369675   0.122204   3.025  0.00358 ** 
Waist.Girth              0.006145   0.012651   0.486  0.62881    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.7379 on 64 degrees of freedom
Multiple R-squared:  0.6479,    Adjusted R-squared:  0.6204 
F-statistic: 23.55 on 5 and 64 DF,  p-value: 2.4e-13
```

Esto confirma que esta variable no aporta al modelo. Siguiendo el
principio de parsimonia, es mejor que lo quitemos (y hacer una revisi√≥n
r√°pida que nada se altera demasiado al introducir este cambio).

``` r
rlm <- update(rlm, . ~ . - Waist.Girth)

cat("Modelo de RLM obtenido:\n")
print(summary(rlm))

cat("\nPrueba de curvatura:\n")
residualPlots(rlm, type = "rstandard", terms = ~ 1, col = "steelblue", pch = 20, col.quad = "red")
```


``` r
cat("\nFactores de inflaci√≥n de la varianza:\n")
print(vif(rlm))

cat("\nPrueba de varianza del error no constante:\n")
ncvTest(rlm)

cat("\nIndependencia de los residuos\n")
print(durbinWatsonTest(rlm))
```

``` bg-ivory
Modelo de RLM obtenido:

Call:
lm(formula = Knees.diameter ~ Wrists.diameter + Bitrochanteric.diameter + 
    Age + Ankles.diameter, data = datos_entren)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.69107 -0.47170  0.04761  0.48962  1.52555 

Coefficients:
                         Estimate Std. Error t value Pr(>|t|)    
(Intercept)              1.321201   1.909073   0.692  0.49136    
Wrists.diameter          0.588980   0.171023   3.444  0.00101 ** 
Bitrochanteric.diameter  0.232096   0.052446   4.425 3.76e-05 ***
Age                     -0.041103   0.009569  -4.296 5.94e-05 ***
Ankles.diameter          0.368992   0.121475   3.038  0.00343 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.7335 on 65 degrees of freedom
Multiple R-squared:  0.6466,    Adjusted R-squared:  0.6249 
F-statistic: 29.73 on 4 and 65 DF,  p-value: 4.585e-14


Prueba de curvatura:
           Test stat Pr(>|Test stat|)
Tukey test    1.6415           0.1007

Factores de inflaci√≥n de la varianza:
        Wrists.diameter Bitrochanteric.diameter                     Age 
               1.525713                1.330286                1.039155 
        Ankles.diameter 
               1.432882 

Prueba de varianza del error no constante:
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.3581494, Df = 1, p = 0.54954

Independencia de los residuos
 lag Autocorrelation D-W Statistic p-value
   1        0.157849      1.674262   0.144
 Alternative hypothesis: rho != 0
```

El nuevo modelo m√°s simple parece mantener el comportamiento del modelo
anterior.

Revisemos ahora si existen casos demasiado influyentes utilizando el
gr√°fico de influencia para identificarlos.

``` r
cat("Rango para 95% de los residuos studentizados: ")
cat("[", round(qt(0.05/2, nrow(datos_entren) - length(coef(rls)) - 1), 3), ", ", sep = "")
cat(round(qt(1-0.05/2, nrow(datos_entren) - length(coef(rls)) - 1), 3), "]\n", sep = "")
cat("L√≠mite del apalancamiento:", round(2 * mean(hatvalues(rlm)), 3), "\n")
cat("L√≠mite de la distancia de Cook:", round(3 * mean(cooks.distance(rlm)), 3), "\n")

rlm_inf <- influencePlot(rlm, id = list(n = 3))
```

``` r
cat("\nCasos notorios para el modelo de RLM:\n")
print(rlm_inf)
```

``` bg-ivory
Rango para 95% de los residuos studentizados: [-1.996, 1.996]
L√≠mite del apalancamiento: 0.143 
L√≠mite de la distancia de Cook: 0.052 

Casos notorios para el modelo de RLM:
      StudRes        Hat       CookD
4   0.8036599 0.20660532 0.033822004
12 -0.4404798 0.19385127 0.009448313
31 -2.4080519 0.06039000 0.069413666
33  2.1969458 0.05115061 0.049145017
42 -1.9497935 0.12542112 0.104532595
43 -0.8832504 0.17477019 0.033155965
64 -2.6023356 0.14554713 0.211896164
```

Y el gr√°fico marginal de los valores predichos (`fitted`) para evaluar
su influencia en el modelo.

``` r
id_inf <- mmp(rlm,
              col = "steelblue", pch = 20, col.line = c("steelblue", "red"),
              smooth = list(smoother=loessLine, span = 1),
              id = list(method = "r", n = 7, cex = 0.7, location = "lr"))
```

Vemos que, a pesar que los casos
4 y 66 curvan la tendencia de los datos hacia arriba, el modelo (l√≠nea
roja segmentada) no parece estar visiblemente modificada por alguno de
los casos notorios identificados.

Notemos que en la funci√≥n que genera el gr√°fico marginal, `mmp()` o su
equivalente `marginalModelPlot()`, usan el argumento `col.line` para
indicar los colores de las curvas ajustadas, primero para la curva
suavizada de los datos y el segundo para la curva del modelo. Sin
embargo, la funci√≥n `crPlots()` que genera los gr√°ficos de residuos por
componente utiliza el par√°metro `col.lines` (plural) para este
prop√≥sito, debiendo indicar primero el color para la curva del modelo y
luego el color para la curva suavizada de los datos. ¬°Qu√© falta de
consistencia! Es el precio de construir bibliotecas en comunidad...

Finalmente, cometemos la bondad de ajuste que alcanza el modelo. Vemos que consigue una reducci√≥n significativa de la variabilidad aleatoria (ùêπ(4;65)=29,7; ùëù<0,001), pues explica alrededor del 65% de la varianza de la variable de salida.

Con todo este an√°lisis podemos dar la siguiente conclusi√≥n.

El modelo de RLM obtenido parece ser confiable, puesto que se ajusta
bien a los datos observados, incluye predictores que muestran una
relaci√≥n lineal con la variable de respuesta, genera residuos que
parecen seguir una distribuci√≥n normal y sin problemas evidentes de
heterocedasticidad o de dependencia entre ellos. Por otro lado, no hay
casos que est√©n dominando el modelo.

\
:::

::: {#comparaci√≥n-de-los-modelos .section .level2}
## Comparaci√≥n de los modelos

Vimos que el modelo de RLS construido logra explicar alrededor del 40% de la variabilidad en los datos, mientras que el RLM que tenemos logra explicar cerca del 65% . Confirmemos si esta es una mejora significativa en la bondad de ajuste.

``` r
cat("Comparaci√≥n de los modelos de RLS y RLM:\n")
print(anova(rls, rlm))
```

``` bg-ivory
Comparaci√≥n de los modelos de RLS y RLM:
Analysis of Variance Table

Model 1: Knees.diameter ~ Wrists.diameter
Model 2: Knees.diameter ~ Wrists.diameter + Bitrochanteric.diameter + 
    Age + Ankles.diameter
  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    
1     68 60.195                                  
2     65 34.976  3    25.219 15.623 9.332e-08 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

Confirmamos entonces que el modelo de RLM consigue una reducci√≥n significativa de la varianza no explicada en los datos con respecto al modelo de RLS (ùêπ(3,65)=15,623;ùëù<0,001).

Veamos si estos niveles de bondad de ajuste se reflejan en la calidad
predictiva de los modelos conseguidos.

Como se indica en el enunciado, es importante hacer esta evaluaci√≥n con datos distintos a los usados en la construcci√≥n de los modelos. Por esta raz√≥n hemos construido los modelos usando 70%
 de los datos disponibles, dejando el resto para hacer esta evaluaci√≥n. As√≠, podemos comparar las predicciones que hacen con datos vistos (los de entrenamiento) y no vistos (los de prueba).

``` r
rls_rmse_entre <- sqrt(mean(resid(rls) ** 2))
rls_preds <- predict(rls, datos_prueba)
rls_res_prueba <- datos_prueba[[nombre_respuesta]] - rls_preds
rls_rmse_prueba <- sqrt(mean(rls_res_prueba ** 2))
rls_pct_cambio <- ((rls_rmse_prueba - rls_rmse_entre) / rls_rmse_entre) * 100

rlm_rmse_entre <- sqrt(mean(resid(rlm) ** 2))
rlm_preds <- predict(rlm, datos_prueba)
rlm_res_prueba <- datos_prueba[[nombre_respuesta]] - rlm_preds
rlm_rmse_prueba <- sqrt(mean(rlm_res_prueba ** 2))
rlm_pct_cambio <- ((rlm_rmse_prueba - rlm_rmse_entre) / rlm_rmse_entre) * 100

cat(sprintf("Resumen de la variable de salida (%s):\n", nombre_respuesta))
print(describe(datos |> pull(all_of(nombre_respuesta)), skew = FALSE))
cat("\n")
cat("Rendimiento del modelo de RLS:\n")
cat(sprintf("RMSE para el conjunto de entrenamiento: %.3f\n", rls_rmse_entre))
cat(sprintf("RMSE para el conjunto de prueba: %.3f\n", rls_rmse_prueba))
cat(sprintf("Cambio en el error: %.1f%%\n", rls_pct_cambio))
cat("\n")
cat("Rendimiento del modelo de RLM:\n")
cat(sprintf("RMSE para el conjunto de entrenamiento: %.3f\n", rlm_rmse_entre))
cat(sprintf("RMSE para el conjunto de prueba: %.3f\n", rlm_rmse_prueba))
cat(sprintf("Cambio en el error: %.1f%%\n", rlm_pct_cambio))
```

``` bg-ivory
Resumen de la variable de salida (Knees.diameter):
   vars   n  mean   sd median  min max range   se
X1    1 100 19.72 1.18  19.55 17.3  23   5.7 0.12

Rendimiento del modelo de RLS:
RMSE para el conjunto de entrenamiento: 0.927
RMSE para el conjunto de prueba: 1.138
Cambio en el error: 22.7%

Rendimiento del modelo de RLM:
RMSE para el conjunto de entrenamiento: 0.707
RMSE para el conjunto de prueba: 1.000
Cambio en el error: 41.5%
```

Podemos observar que, efectivamente, el modelo de RLM obtiene menores tasas de error que el modelo de RLS. Sin embargo, esta disminuci√≥n es m√°s acentuada en los datos de entrenamiento y no se exhibe de igual magnitud en los de prueba. Por otro lado, un error de ¬±1,0 podr√≠a ser alto si se considera que el rango de la variable de salida (17,3‚Äì23,0) es de solo 5,7. As√≠, podemos concluir lo siguiente.

::: conclusion
El modelo de RLM logra mejorar el rendimiento del modelo de RLS pero hay indicios de sobreajuste en √©l, ya que el error aumenta m√°s de un 40%
 al pasar de datos vistos a datos no vistos. La calidad predictiva del modelo tampoco parece ser muy buena.

A pesar de que este modelo de RLM result√≥ confiable, parece tener problemas de generalizaci√≥n y calidad predictiva.
:::

Lo que corresponder√≠a entonces es analizar la eliminaci√≥n de uno o dos
de los predictores y evaluar nuevamente la confiabilidad y el poder
predictivo del nuevo modelo de RLM. *Esto se deja como ejercicio.*

\
:::

::: {#referencias .section .level2}
## Referencias

Heinz, G., Peterson, L. J., Johnson, R. W., & Kerk, C. J. (2003).
Exploring relationships in body dimensions. Journal of Statistics
Education, 11(2).
:::
:::

::: {style="position: absolute; width: 0px; height: 0px; overflow: hidden; padding: 0px; border: 0px; margin: 0px;"}
::: {#MathJax_Font_Test style="position: absolute; visibility: hidden; top: 0px; left: 0px; width: auto; min-width: 0px; max-width: none; padding: 0px; border: 0px; margin: 0px; white-space: nowrap; text-align: left; text-indent: 0px; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; font-size: 40px; font-weight: normal; font-style: normal; font-size-adjust: none; font-family: STIXSizeOneSym, sans-serif;"}
:::
:::
